{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: syllapy in c:\\users\\focus\\develop\\cu\\dtsa-5511\\final\\.venv\\lib\\site-packages (0.7.2)\n","Requirement already satisfied: ety in c:\\users\\focus\\develop\\cu\\dtsa-5511\\final\\.venv\\lib\\site-packages (1.4.0)\n","Requirement already satisfied: treelib in c:\\users\\focus\\develop\\cu\\dtsa-5511\\final\\.venv\\lib\\site-packages (from ety) (1.7.0)\n","Requirement already satisfied: colorful in c:\\users\\focus\\develop\\cu\\dtsa-5511\\final\\.venv\\lib\\site-packages (from ety) (0.5.5)\n","Requirement already satisfied: six in c:\\users\\focus\\develop\\cu\\dtsa-5511\\final\\.venv\\lib\\site-packages (from ety) (1.16.0)\n","Requirement already satisfied: colorama in c:\\users\\focus\\develop\\cu\\dtsa-5511\\final\\.venv\\lib\\site-packages (from colorful->ety) (0.4.6)\n"]}],"source":["!pip install syllapy\n","!pip install ety"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\focus\\Develop\\CU\\DTSA-5511\\final\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\focus\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\focus\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\focus\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import nltk\n","from collections import Counter\n","import syllapy\n","from nltk.corpus import wordnet\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import ety\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","from transformers import (\n","    BertTokenizer,\n","    TFBertModel,\n","    XLMRobertaTokenizer,\n","    TFXLMRobertaModel,\n",")\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import (\n","    Embedding,\n","    Bidirectional,\n","    LSTM,\n","    Dense,\n","    Dropout,\n","    Input,\n","    Flatten,\n","    concatenate,\n","    BatchNormalization,\n",")\n","from keras import regularizers\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.models import Model\n","\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","tqdm.pandas()\n","nltk.download(\"wordnet\")\n","nltk.download(\"punkt\")\n","nltk.download(\"averaged_perceptron_tagger\")"]},{"cell_type":"markdown","metadata":{},"source":["## Read and Process Data"]},{"cell_type":"markdown","metadata":{},"source":["Below, I pre-process the text data along with performing feature extraction.  The following code takes text input, performs various operations on it, and returns a set of linguistic statistics and processed data.\n","\n","The following code:\n","\n","- Converts the input text to lowercase\n","- Tokenizes the text into sentences using the Natural Language Toolkit (`nltk`), and each sentence is further tokenized into words. POS tags are assigned to each word.\n","- For each word in the text, the code does the following:\n","  - Determines the word's origin language (etymology).\n","  - Retrieves the full name of the POS tag from the `pos_mapping`.\n","  - Counts the number of syllables in the word.\n","  - Calculates the length of the word.\n","- Calculates various linguistic statistics, such as the mean syllable count, the number of sentences, the mean sentence length, the mean word length, and the total number of words."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\n","    \"./kaggle/input/clear-corpus-6-01-clear-corpus-6-01/CLEAR Corpus 6.01 - CLEAR Corpus 6.01.csv\"\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["pos_mapping = {\n","    \"CC\": \"Coordinating Conjunction\",\n","    \"CD\": \"Cardinal Digit\",\n","    \"DT\": \"Determiner\",\n","    \"EX\": \"Existential There\",\n","    \"FW\": \"Foreign Word\",\n","    \"IN\": \"Preposition or Subordinating Conjunction\",\n","    \"JJ\": \"Adjective\",\n","    \"JJR\": \"Adjective, Comparative\",\n","    \"JJS\": \"Adjective, Superlative\",\n","    \"LS\": \"List Item Marker\",\n","    \"MD\": \"Modal\",\n","    \"NN\": \"Noun, Singular or Mass\",\n","    \"NNS\": \"Noun, Plural\",\n","    \"NNP\": \"Proper Noun, Singular\",\n","    \"NNPS\": \"Proper Noun, Plural\",\n","    \"PDT\": \"Predeterminer\",\n","    \"POS\": \"Possessive Ending\",\n","    \"PRP\": \"Personal Pronoun\",\n","    \"PRP$\": \"Possessive Pronoun\",\n","    \"RB\": \"Adverb\",\n","    \"RBR\": \"Adverb, Comparative\",\n","    \"RBS\": \"Adverb, Superlative\",\n","    \"RP\": \"Particle\",\n","    \"TO\": \"to\",\n","    \"UH\": \"Interjection\",\n","    \"VB\": \"Verb, Base Form\",\n","    \"VBD\": \"Verb, Past Tense\",\n","    \"VBG\": \"Verb, Gerund or Present Participle\",\n","    \"VBN\": \"Verb, Past Participle\",\n","    \"VBP\": \"Verb, Non-3rd Person Singular Present\",\n","    \"VBZ\": \"Verb, 3rd Person Singular Present\",\n","    \"WDT\": \"Wh-determiner\",\n","    \"WP\": \"Wh-pronoun\",\n","    \"WP$\": \"Possessive Wh-pronoun\",\n","    \"WRB\": \"Wh-adverb\",\n","}\n","\n","\n","def process_text(text):\n","    text = text.lower()\n","\n","    word_origins = []\n","    word_pos = []\n","    syllable_counts = []\n","    sentence_lengths = []\n","    word_lengths = []\n","\n","    sentences = sent_tokenize(text)\n","\n","    for sentence in sentences:\n","        tokens = nltk.word_tokenize(sentence)\n","        pos_tags = nltk.pos_tag(tokens)\n","        sentence_lengths.append(len(pos_tags))\n","        for token, pos in pos_tags:\n","            origin = ety.origins(token)\n","            if origin:\n","                origin = origin[0].language.name\n","            else:\n","                origin = \"unknown\"\n","            word_origins.append(origin)\n","            full_pos_name = pos_mapping.get(pos, pos)\n","            word_pos.append(full_pos_name)\n","            syllables = syllapy.count(token)\n","            syllable_counts.append(syllables)\n","            word_lengths.append(len(token))\n","\n","    processed_excerpt = text\n","    origin_counts = Counter(word_origins)\n","    pos_counts = Counter(word_pos)\n","    mean_syllable_count = np.mean(syllable_counts)\n","    num_sentences = len(sentences)\n","    mean_sentence_length = np.mean(sentence_lengths)\n","    num_words = np.sum(sentence_lengths)\n","    mean_word_length = np.mean(word_lengths)\n","\n","    return (\n","        word_origins,\n","        origin_counts,\n","        word_pos,\n","        pos_counts,\n","        syllable_counts,\n","        mean_syllable_count,\n","        num_sentences,\n","        mean_sentence_length,\n","        mean_word_length,\n","        num_words,\n","        processed_excerpt,\n","    )"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4724/4724 [02:07<00:00, 37.05it/s]\n"]}],"source":["df[\n","    [\n","        \"word_origins\",\n","        \"word_origin_counts\",\n","        \"pos\",\n","        \"pos_counts\",\n","        \"syllable_counts\",\n","        \"mean_syllable_count\",\n","        \"num_sentences\",\n","        \"mean_sentence_length\",\n","        \"mean_word_length\",\n","        \"num_words\",\n","        \"processed_excerpt\",\n","    ]\n","] = df[\"Excerpt\"].progress_apply(lambda x: pd.Series(process_text(x)))"]},{"cell_type":"markdown","metadata":{},"source":["## XGBoost Model\n","\n","Below, I prepare text data for the machine learning model.\n","\n","- **Extract Engineered Features:** I extract the sentence features, Parts of Speech counts, and language origin counts engineered above.\n","- **Train Model:** Train XGBoost model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Squared Error: 0.6942651631843457\n"]}],"source":["sentence_features = df[\n","    [\n","        \"mean_syllable_count\",\n","        \"num_sentences\",\n","        \"mean_sentence_length\",\n","        \"mean_word_length\",\n","    ]\n","]\n","\n","sentence_features = sentence_features.join(\n","    pd.DataFrame(df[\"pos_counts\"].tolist()).fillna(0)\n",")\n","\n","sentence_features = sentence_features.join(\n","    pd.DataFrame(df[\"word_origin_counts\"].tolist()).fillna(0)\n",")\n","\n","labels = np.array(df[\"BT Easiness\"])\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    sentence_features, labels, test_size=0.2, random_state=42\n",")\n","model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","mse = mean_squared_error(y_test, y_pred)\n","print(f\"Mean Squared Error: {mse}\")"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
